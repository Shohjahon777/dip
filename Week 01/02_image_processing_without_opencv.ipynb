{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Lesson 02: Image Processing Without OpenCV\n",
    "\n",
    "Before relying on high-level libraries, it's important to understand that **images are just NumPy arrays**.  \n",
    "In this notebook we perform image operations using **only NumPy** — no OpenCV functions.\n",
    "\n",
    "This builds intuition for what OpenCV is doing under the hood.\n",
    "\n",
    "## Topics:\n",
    "- Images as arrays\n",
    "- Manual grayscale conversion\n",
    "- Manual brightness / contrast adjustment\n",
    "- Manual cropping and flipping\n",
    "- Manual channel manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image   # only used for loading — no processing\n",
    "\n",
    "# Load image as numpy array (RGB) using PIL\n",
    "pil_img = Image.open('sealion_hero.png').convert('RGB')\n",
    "img = np.array(pil_img, dtype=np.uint8)\n",
    "\n",
    "print(f'Array shape: {img.shape}')    # (H, W, 3)\n",
    "print(f'Data type:   {img.dtype}')    # uint8\n",
    "print(f'Min / Max:   {img.min()} / {img.max()}')\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image (loaded as numpy array)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## 1. Grayscale Conversion — Manual\n",
    "\n",
    "The standard luminance formula (ITU-R BT.601):\n",
    "$$\n",
    "\\text{Gray} = 0.299 \\cdot R + 0.587 \\cdot G + 0.114 \\cdot B\n",
    "$$\n",
    "Green gets the highest weight because the human eye is most sensitive to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual grayscale using the luminance formula\n",
    "R = img[:, :, 0].astype(np.float32)\n",
    "G = img[:, :, 1].astype(np.float32)\n",
    "B = img[:, :, 2].astype(np.float32)\n",
    "\n",
    "gray_manual = (0.299 * R + 0.587 * G + 0.114 * B).astype(np.uint8)\n",
    "\n",
    "# Compare: simple average vs proper formula\n",
    "gray_avg = ((R + G + B) / 3).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "axes[0].imshow(img);                      axes[0].set_title('Original RGB');   axes[0].axis('off')\n",
    "axes[1].imshow(gray_avg, cmap='gray');    axes[1].set_title('Simple Average'); axes[1].axis('off')\n",
    "axes[2].imshow(gray_manual, cmap='gray'); axes[2].set_title('Luminance Formula (0.299R + 0.587G + 0.114B)'); axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## 2. Brightness Adjustment — Manual\n",
    "\n",
    "Adding or subtracting a constant from each pixel.  \n",
    "We must **clip** values to stay in [0, 255] to avoid overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness(image, delta):\n",
    "    \"\"\"Add delta to all pixels and clip to [0, 255].\"\"\"\n",
    "    result = image.astype(np.int16) + delta\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "bright = adjust_brightness(img, +80)\n",
    "dark   = adjust_brightness(img, -80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "axes[0].imshow(img);    axes[0].set_title('Original');   axes[0].axis('off')\n",
    "axes[1].imshow(bright); axes[1].set_title('+80 Brightness'); axes[1].axis('off')\n",
    "axes[2].imshow(dark);   axes[2].set_title('−80 Brightness'); axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "## 3. Contrast Adjustment — Manual\n",
    "\n",
    "Multiplying pixel values by a factor scales the contrast:\n",
    "- Factor > 1.0 → increases contrast (darks darker, brights brighter)\n",
    "- Factor < 1.0 → decreases contrast (range compresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_contrast(image, factor):\n",
    "    \"\"\"Multiply all pixels by factor and clip to [0, 255].\"\"\"\n",
    "    result = image.astype(np.float32) * factor\n",
    "    return np.clip(result, 0, 255).astype(np.uint8)\n",
    "\n",
    "low_contrast  = adjust_contrast(img, 0.5)\n",
    "high_contrast = adjust_contrast(img, 1.8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "axes[0].imshow(img);           axes[0].set_title('Original');        axes[0].axis('off')\n",
    "axes[1].imshow(low_contrast);  axes[1].set_title('Low contrast ×0.5'); axes[1].axis('off')\n",
    "axes[2].imshow(high_contrast); axes[2].set_title('High contrast ×1.8'); axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## 4. Cropping and Flipping — Manual (Pure NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img.shape[:2]\n",
    "\n",
    "# Crop: numpy slice [y_start:y_end, x_start:x_end]\n",
    "crop = img[h//4 : 3*h//4, w//4 : 3*w//4]\n",
    "\n",
    "# Horizontal flip: reverse columns\n",
    "flip_h = img[:, ::-1, :]\n",
    "\n",
    "# Vertical flip: reverse rows\n",
    "flip_v = img[::-1, :, :]\n",
    "\n",
    "# Both flips\n",
    "flip_both = img[::-1, ::-1, :]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for ax, (im, t) in zip(axes, [\n",
    "    (crop,      'Cropped (center)'),\n",
    "    (flip_h,    'Flip horizontal'),\n",
    "    (flip_v,    'Flip vertical'),\n",
    "    (flip_both, 'Flip both'),\n",
    "]):\n",
    "    ax.imshow(im); ax.set_title(t); ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3a4b5",
   "metadata": {},
   "source": [
    "## 5. Channel Manipulation — Manual\n",
    "\n",
    "Images have 3 color channels (R, G, B).  \n",
    "We can isolate or zero out individual channels to see their contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate each channel (keep one, set others to 0)\n",
    "red_only   = img.copy(); red_only[:, :, 1] = 0;   red_only[:, :, 2] = 0\n",
    "green_only = img.copy(); green_only[:, :, 0] = 0;  green_only[:, :, 2] = 0\n",
    "blue_only  = img.copy(); blue_only[:, :, 0] = 0;   blue_only[:, :, 1] = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axes[0].imshow(img);        axes[0].set_title('Original');    axes[0].axis('off')\n",
    "axes[1].imshow(red_only);   axes[1].set_title('Red channel'); axes[1].axis('off')\n",
    "axes[2].imshow(green_only); axes[2].set_title('Green channel'); axes[2].axis('off')\n",
    "axes[3].imshow(blue_only);  axes[3].set_title('Blue channel'); axes[3].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## 6. Image Negative (Inversion)\n",
    "\n",
    "The **negative** of an image flips all pixel intensities:  \n",
    "$$\\text{neg}(x, y) = 255 - I(x, y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = 255 - img\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(img);      axes[0].set_title('Original'); axes[0].axis('off')\n",
    "axes[1].imshow(negative); axes[1].set_title('Negative (255 - img)'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 7. Float32 vs uint8 — Why It Matters\n",
    "\n",
    "When doing math on uint8 arrays, overflow wraps around (255 + 1 = 0)!  \n",
    "Always convert to float32 for calculations, then clip and convert back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dangerous: uint8 overflow\n",
    "overflow_bad = img + np.uint8(100)   # wraps around!\n",
    "\n",
    "# Safe: use float32 + clip\n",
    "overflow_safe = np.clip(img.astype(np.float32) + 100, 0, 255).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "axes[0].imshow(img);            axes[0].set_title('Original');                  axes[0].axis('off')\n",
    "axes[1].imshow(overflow_bad);   axes[1].set_title('+100 (uint8 wrap — WRONG)'); axes[1].axis('off')\n",
    "axes[2].imshow(overflow_safe);  axes[2].set_title('+100 (float+clip — CORRECT)'); axes[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Images are **NumPy arrays** — shape `(H, W, 3)` for color, `(H, W)` for grayscale\n",
    "- Operations are just **array math**: slicing = crop, `[::-1]` = flip, etc.\n",
    "- Always work in **float32** when computing, then convert back to **uint8** with `np.clip(..., 0, 255)`\n",
    "- OpenCV functions are convenience wrappers around these exact same operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
